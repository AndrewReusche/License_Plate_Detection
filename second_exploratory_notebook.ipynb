{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8kyU3aIZJupo"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "username = 'Andrew_Reusche92'\n",
        "api_key = '63cd28af853827307d2b6546dd833488'\n",
        "\n",
        "api_token = {\"username\":username,\"key\":api_key}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ronakgohil/license-plate-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__CbOZ8nURm7",
        "outputId": "785f7a6f-1bfd-47b6-b5fe-8ac57b442971"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ronakgohil/license-plate-dataset\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q license-plate-dataset.zip -d data"
      ],
      "metadata": {
        "id": "3iog-l-xUVUk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XHCOAAHaEDr",
        "outputId": "4d51116b-54b9-4867-fc40-66421f2e5874"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import some libraries that may be useful\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from scikeras.wrappers import KerasRegressor"
      ],
      "metadata": {
        "id": "ME6EUO_DUayi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the data path\n",
        "base_path= 'data/archive'\n",
        "train_img_path= os.path.join(base_path, 'images', 'train')\n",
        "val_img_path= os.path.join(base_path, 'images', 'val')\n",
        "train_label_path= os.path.join(base_path, 'labels', 'train')\n",
        "val_label_path= os.path.join(base_path, 'labels', 'val')"
      ],
      "metadata": {
        "id": "E5jMrFvfYGdh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the image size we want to transfrom all the image sizes to\n",
        "img_size= 224 #pixels"
      ],
      "metadata": {
        "id": "WXKp8EyXnpif"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create function to load in the data\n",
        "def load_data(img_folder, label_folder):\n",
        "  images= []\n",
        "  labels= []\n",
        "  img_files= sorted([f for f in os.listdir(img_folder) if f.endswith('.jpg')])\n",
        "\n",
        "  for img_file in img_files:\n",
        "\n",
        "    #load image\n",
        "    img_path= os.path.join(img_folder, img_file)\n",
        "    img= cv2.imread(img_path)\n",
        "\n",
        "    #change image color and shape\n",
        "    img= cv2.resize(img, (img_size, img_size))\n",
        "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_height, img_width, _= img.shape\n",
        "\n",
        "    #load labels\n",
        "    label_file= img_file.replace('.jpg', '.txt')\n",
        "    label_path= os.path.join(label_folder, label_file)\n",
        "    if os.path.exists(label_path):\n",
        "      with open(label_path, 'r') as f:\n",
        "\n",
        "        #read in YOLO format\n",
        "        line= f.readline().strip().split()\n",
        "\n",
        "        if len(line) == 5:\n",
        "          class_id, x_center, y_center, width, height= map(float, line)\n",
        "\n",
        "          #convert YOLO to absolute pixel value\n",
        "          x_center *= img_width\n",
        "          y_center *= img_height\n",
        "          width *= img_width\n",
        "          height *= img_height\n",
        "\n",
        "          #convert to coordinates\n",
        "          x_min= x_center - (width/2)\n",
        "          y_min= y_center - (height/2)\n",
        "          x_max= x_center + (width/2)\n",
        "          y_max= y_center + (height/2)\n",
        "\n",
        "          #scale coordinates to resized image\n",
        "          scale_x= img_size / img_width\n",
        "          scale_y= img_size / img_height\n",
        "          x_min *= scale_x\n",
        "          y_min *= scale_y\n",
        "          x_max *= scale_x\n",
        "          y_max *= scale_y\n",
        "\n",
        "          #add coordinates and images to lists\n",
        "          labels.append([x_min, y_min, x_max, y_max])\n",
        "          images.append(img)\n",
        "\n",
        "  return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "suO-3FFjbaRf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load in and split the data\n",
        "\n",
        "#original training data\n",
        "train_images, train_labels= load_data(train_img_path, train_label_path)\n",
        "#validation data\n",
        "val_images, val_labels= load_data(val_img_path, val_label_path)\n",
        "\n",
        "#train-test-split the train to make a new test set from 10% of the original train\n",
        "train_images, test_images, train_labels, test_labels= train_test_split(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    test_size= 0.1,\n",
        "    random_state= 24)\n",
        "\n",
        "#print out the length of each new data subset\n",
        "print(f'Training set: {len(train_images)} images')\n",
        "print(f'Validation set: {len(val_images)} images')\n",
        "print(f'Test set: {len(test_images)} images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeUmTmUfg72u",
        "outputId": "0aae8c23-5709-45c7-9928-5447b16ed061"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 1197 images\n",
            "Validation set: 169 images\n",
            "Test set: 134 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycWHjEwijFO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}